{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Square GNN Experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMAGENTS = 30\n",
    "NUMEXPERIMENTS = 100\n",
    "TIME = 25 # seconds\n",
    "VISUAL = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import simulation.Visualizer\n",
    "import simulation.World\n",
    "import simulation.Agent\n",
    "import pickle\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "simulation.Agent.USE = \"SIM\"\n",
    "simulation.Agent.CASE = \"SQU\"\n",
    "\n",
    "for i in range(NUMEXPERIMENTS):\n",
    "    if i%10== 0:\n",
    "        print(str(i)+\"/\"+str(NUMEXPERIMENTS))\n",
    "    filename = \"./data/squ-logs/experiment-\"+str(i)+\"-log.p\"\n",
    "    with open(filename, \"wb\") as f:\n",
    "        world = simulation.World.World(f)\n",
    "        for j in range(int(NUMAGENTS)):\n",
    "            a = simulation.Agent.Agent(swarm=j%2)\n",
    "            world.agents.append(a)\n",
    "\n",
    "        if VISUAL:\n",
    "            v = simulation.Visualizer.Visualizer(world)\n",
    "            v.run()\n",
    "        else:\n",
    "            while world.stepCount < TIME*10:\n",
    "                world.step()\n",
    "            world.closeWorld()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "y5hFgzapZl-u",
    "outputId": "49a5e715-e36d-473c-c77d-e5ccafbac24b",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "from utils.SquDataset import SquDataset\n",
    "\n",
    "###############################\n",
    "###  Gather and split data  ###\n",
    "###############################\n",
    "\n",
    "ta = 70 # Percentage used for training\n",
    "te = 15 # Percentage used for testing (remaining used for validation)\n",
    "\n",
    "try:\n",
    "    shutil.rmtree(\"/tmp/Squares\", ignore_errors=False, onerror=None)\n",
    "except FileNotFoundError as e:\n",
    "    pass\n",
    "    \n",
    "dataset = SquDataset(root='/tmp/Squares').shuffle()\n",
    "maxSize = 5000\n",
    "dataset = dataset[:min(len(dataset), maxSize)]\n",
    "\n",
    "train_data = dataset[0:int(ta/100.*len(dataset))]\n",
    "test_data = dataset[int(ta/100.*len(dataset)):int((ta+te)/100.*len(dataset))]\n",
    "validate_data = dataset[int((ta+te)/100.*len(dataset)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data, DataLoader\n",
    "from utils.models import *\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "from time import sleep\n",
    "\n",
    "np.random.seed(1337)\n",
    "\n",
    "num_epochs = 200\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "trainLoader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "testLoader = DataLoader(test_data, batch_size=32, shuffle=True)\n",
    "\n",
    "node_dim = train_data[0].x.shape[1]\n",
    "edge_dim = 0\n",
    "if train_data[0].edge_attr is not None: # if edge attributes used\n",
    "    edge_dim = train_data[0].edge_attr.shape[1]\n",
    "out_dim = train_data[0].y.shape[1]\n",
    "\n",
    "mod = GenericGNN(node_dim, edge_dim, out_dim)\n",
    "optimizer = torch.optim.Adam(mod.parameters(), lr=4e-5, weight_decay=5e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1bs7l6xYZl_T",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from random import random\n",
    "from copy import deepcopy as copy\n",
    "from tqdm import tqdm\n",
    "from time import sleep\n",
    "import torch.nn as nn\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (12, 4)\n",
    "\n",
    "lossFunction = nn.MSELoss()\n",
    "\n",
    "def train(model, optimizer, dataset):\n",
    "    \n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    num_items = 1\n",
    "        \n",
    "    for row in dataset:\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(row.x, \n",
    "                     row.edge_index, \n",
    "                     row.edge_attr)\n",
    "        loss = lossFunction(row.y, pred)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        num_items += 1\n",
    "    return total_loss/num_items\n",
    "\n",
    "def evaluate(model, dataset):\n",
    "    \n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    total_loss = 0.0\n",
    "    num_items = 0\n",
    "    \n",
    "    num_outs = dataset[0].y.shape[1]\n",
    "    \n",
    "    predHist = [[] for _ in range(num_outs)]\n",
    "    actualHist = [[] for _ in range(num_outs)]    \n",
    "\n",
    "    for row in dataset:\n",
    "        pred = model(row.x, \n",
    "                 row.edge_index, \n",
    "                 row.edge_attr)\n",
    "        loss = lossFunction(row.y, pred)\n",
    "\n",
    "        for i in range(len(pred[0])):\n",
    "            predHist[i].append(pred[0][i].item())\n",
    "            actualHist[i].append(row.y[0][i].item())\n",
    "            \n",
    "        total_loss += loss.item()\n",
    "        num_items += 1\n",
    "        \n",
    "    return total_loss/num_items, actualHist, predHist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 30\n",
    "epoch = 0\n",
    "nbins  = 100\n",
    "minmax = 0.5\n",
    "bins  = [((i*(minmax*2))/nbins) - minmax for i in range(nbins+1)]\n",
    "losses = []\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [5, 3]\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "\n",
    "for epoch in tqdm(range(epoch, num_epochs)):\n",
    "       \n",
    "    train_loss      = train(   mod, optimizer, train_data)\n",
    "    test_loss, a, p = evaluate(mod,            test_data)\n",
    "    \n",
    "    losses.append([train_loss, test_loss])\n",
    "    \n",
    "    print(\"{train: \" + str(train_loss) +\"}, {test: \" + str(test_loss) + \"}\")\n",
    "    \n",
    "    plt.rcParams['figure.figsize'] = (5, 3)    \n",
    "    fig, ax = plt.subplots(1,1)\n",
    "    fig.suptitle(\"Testing dataset\", fontsize=16)\n",
    "    ax.hist(p[0], bins=bins, alpha=0.5, label=\"predicted\")\n",
    "    ax.hist(a[0], bins=bins, alpha=0.5, label=\"actual\")\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    torch.save(mod.state_dict(), './models/squ-models/SQU-'+str(epoch)+'.mod')\n",
    "    sleep(0.5)\n",
    "    \n",
    "torch.save(mod.state_dict(), './models/squ-models/SQU-FINAL.mod')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([i for i in range(len(losses))],[losses[i][0] for i in range(len(losses))])\n",
    "plt.plot([i for i in range(len(losses))],[losses[i][1] for i in range(len(losses))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mod = GenericGNN(node_dim, edge_dim, out_dim)\n",
    "mod.load_state_dict(torch.load('./models/squ-models/SQU-1.mod'))\n",
    "mod.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapoints = 10000\n",
    "from random import random\n",
    "import math\n",
    "\n",
    "dataFileName = 'randomData.csv'\n",
    "dataString = ''\n",
    "\n",
    "MULT = 1\n",
    "TARGET_DIST = 0.15 \n",
    "HYP = math.sqrt(pow(TARGET_DIST,2)+pow(TARGET_DIST,2))\n",
    "DIP = 1 \n",
    "\n",
    "\n",
    "def lj(x, e, t=None):\n",
    "    \n",
    "    if t is None:\n",
    "        t = TARGET_DIST\n",
    "    \n",
    "    dist = math.sqrt(((x[1][0]-x[0][0])**2)+((x[1][1]-x[0][1])**2))\n",
    "    epsilon = DIP*MULT\n",
    "    sigma = (t*MULT)/(2**(1/6))\n",
    "    mag = min((epsilon*4) * (pow((sigma/dist),12)-pow((sigma/dist),6)), 10)\n",
    "    \n",
    "    angle = 0\n",
    "    if mag < 0:\n",
    "        angle = math.pi\n",
    "    \n",
    "    return mag, angle\n",
    "\n",
    "minDist = 0.1\n",
    "maxDist = 0.4\n",
    "\n",
    "mod.eval()\n",
    "\n",
    "mod.to('cpu')\n",
    "\n",
    "scatterX = []\n",
    "scatterY = []\n",
    "scatterA = []\n",
    "scatterY2 = []\n",
    "scatterA2 = []\n",
    "scatterAA = []\n",
    "scatterAY = []\n",
    "scatterAA2 = []\n",
    "scatterAY2 = []\n",
    "\n",
    "\n",
    "ljX = []\n",
    "ljY = []\n",
    "ljY2 = []\n",
    "for i in range(1000):\n",
    "    delta = (maxDist-minDist)/1000\n",
    "    ljX.append(minDist + (i*delta))\n",
    "    m,a = lj([[0, 0], [ljX[-1], 0]], [])\n",
    "    m2,a2 = lj([[0, 0], [ljX[-1], 0]], [], HYP)\n",
    "    ljY.append(m)\n",
    "    ljY2.append(m2)\n",
    "\n",
    "for i in range(datapoints):\n",
    "    \n",
    "    data = [[0, 0] for _ in range(7)]\n",
    "    \n",
    "    ox = random()\n",
    "    oy = random()\n",
    "    d = (maxDist-minDist) * random() + minDist\n",
    "    scatterX.append(d)\n",
    "    a = random() * (2*math.pi)\n",
    "    no = ox + d*math.cos(a)\n",
    "    ny = oy + d*math.sin(a)\n",
    "    \n",
    "    data[0] = [ox, oy]\n",
    "    data[1] = [no, ny]    \n",
    "    \n",
    "    e1 = [0, 1]\n",
    "    e2 = [1, 0]\n",
    "    \n",
    "    x = torch.tensor(data, dtype=torch.float)\n",
    "    e = torch.tensor([e1, e2], dtype=torch.long)\n",
    "    a1 = torch.tensor([[1], [1]], dtype=torch.float)\n",
    "    a2 = torch.tensor([[2], [2]], dtype=torch.float)\n",
    "    pred1 = mod(x, e, a1)\n",
    "    pred2 = mod(x, e, a2)\n",
    "    ljM, ljA = lj(x, e)\n",
    "    ljM2, ljA2 = lj(x, e, HYP)\n",
    "    \n",
    "    mag = math.sqrt(pred1[0][0]**2 + pred1[0][1]**2)\n",
    "    ang = math.atan2(pred1[0][1], pred1[0][0]) - math.atan2(oy-ny, ox-no)\n",
    "    mag2 = math.sqrt(pred2[0][0]**2 + pred2[0][1]**2)\n",
    "    ang2 = math.atan2(pred2[0][1], pred2[0][0]) - math.atan2(oy-ny, ox-no)\n",
    "    \n",
    "    if ang < 0:\n",
    "        ang = -ang\n",
    "    if ang > math.pi:\n",
    "        ang = ang-math.pi\n",
    "        ang = -ang\n",
    "        ang = ang+math.pi\n",
    "    if ang > math.pi/2:\n",
    "        mag = -mag\n",
    "        \n",
    "    if ang2 < 0:\n",
    "        ang2 = -ang2\n",
    "    if ang2 > math.pi:\n",
    "        ang2 = ang2-math.pi\n",
    "        ang2 = -ang2\n",
    "        ang2 = ang2+math.pi\n",
    "    if ang2 > math.pi/2:\n",
    "        mag2 = -mag2\n",
    "        \n",
    "    scatterY.append(mag)\n",
    "    scatterA.append(ang)\n",
    "    scatterY2.append(mag2)\n",
    "    scatterA2.append(ang2)\n",
    "    scatterAA.append(ljA)\n",
    "    scatterAY.append(ljM)\n",
    "    scatterAA2.append(ljA2)\n",
    "    scatterAY2.append(ljM2)\n",
    "    \n",
    "plt.rcParams['figure.figsize'] = [5, 4]\n",
    "plt.rcParams['figure.dpi'] = 100 # 200 e.g. is really fine, but slower\n",
    "\n",
    "ys= -1.2\n",
    "ye = 1\n",
    "\n",
    "plt.title('Magnitude of Acceleration for Square Lattice')\n",
    "plt.plot([0.5, 0.5], [ys, ye], 'k--')\n",
    "plt.xlabel(\"Distance Between Two Agents\")\n",
    "plt.ylabel(\"Magnitude of Acceleration\")\n",
    "plt.xlim([minDist, maxDist])\n",
    "plt.ylim([ys, ye])\n",
    "plt.scatter(scatterX, scatterY, s=1, alpha=0.2, label='Neighbors k=1')\n",
    "plt.scatter(scatterX, scatterY2, s=1, alpha=0.2, label='Neighbors k=2')\n",
    "plt.plot(ljX, ljY, 'r--', label='Actual LJ Potentials')\n",
    "plt.plot(ljX, ljY2, 'r--')\n",
    "plt.plot([minDist, maxDist], [0, 0], 'k--')\n",
    "plt.legend()\n",
    "\n",
    "s1 = \"\"\n",
    "s2 = \"\"\n",
    "for i in range(len(scatterX)):\n",
    "    s1 += str(scatterX[i])+\",\"+str(scatterY[i]) + \"\\n\"\n",
    "    s2 += str(scatterX[i])+\",\"+str(scatterY2[i]) + \"\\n\"\n",
    "\n",
    "with open(\"./data/MME-data/SQUAREDATA1.csv\", \"w\") as f:\n",
    "    f.write(s1)\n",
    "with open(\"./data/MME-data/SQUAREDATA2.csv\", \"w\") as f:\n",
    "    f.write(s2)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "lEKUuuYfTjP5",
    "IXpsg0LUb2sT",
    "9RTQhSJDbfLZ",
    "kdgdkJwFZl-V",
    "Zw9W7SB-Zl-i",
    "ARWJg6SbZl-n",
    "1PRxdcqSZl-z",
    "Fz05x2HLT5Kg",
    "kBtdfcvgZl_F",
    "gTHRRgTuZl_K",
    "g46wRgIWZl_S",
    "RszfVgfhZl_a",
    "WK5_u9F7UttT",
    "yyduWbndZl_e",
    "hSqOrC1WZl_l",
    "w12Qg4t_em8w",
    "Y4EzD79nU8DO",
    "Uxtqu4E4erXd"
   ],
   "name": "GN_Demo",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
