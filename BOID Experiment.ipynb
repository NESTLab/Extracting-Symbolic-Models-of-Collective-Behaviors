{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BOID GNN Experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VISUALIZE = False\n",
    "NUM_EXPERIMENTS = 100\n",
    "N_BOIDS=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simulation.Boids import *\n",
    "import simulation.Boids\n",
    "import pygame\n",
    "\n",
    "if VISUALIZE:\n",
    "    pygame.init()\n",
    "    clock = pygame.time.Clock()\n",
    "\n",
    "simScreen = None\n",
    "\n",
    "for i in range(NUM_EXPERIMENTS):\n",
    "    if VISUALIZE:\n",
    "        simScreen = pygame.display.set_mode((WIDTH, HEIGHT))\n",
    "        simScreen.fill((255, 255, 255))\n",
    "    simflock = Flock(N_BOIDS, simScreen, VISUALIZE)\n",
    "\n",
    "    step = 0\n",
    "    fileData = \"\"\n",
    "    while True:\n",
    "        if VISUALIZE:\n",
    "            for event in pygame.event.get():\n",
    "                if event.type == pygame.QUIT:\n",
    "                    pygame.quit()\n",
    "                    sys.exit()\n",
    "                    \n",
    "        simS = simflock.run(step)\n",
    "        fileData += simS\n",
    "\n",
    "        step += 1\n",
    "        if VISUALIZE:\n",
    "            pygame.display.update()\n",
    "            clock.tick(FPS)\n",
    "        if step >= (SECONDS * FPS):\n",
    "            print(\"Done with \" + str(i+1) + \" out of \" + str(NUM_EXPERIMENTS))\n",
    "            break\n",
    "\n",
    "    with open(\"./data/boid-logs/experiment-\" + str(i) + \"-log.csv\", \"w\") as f:\n",
    "        f.write(fileData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "y5hFgzapZl-u",
    "outputId": "49a5e715-e36d-473c-c77d-e5ccafbac24b",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###############################\n",
    "####       Pre-reqs        ####\n",
    "###############################\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch.autograd import Variable\n",
    "from matplotlib import pyplot as plt\n",
    "from os import listdir, remove\n",
    "from os.path import join, isfile\n",
    "import pickle\n",
    "import shutil\n",
    "import torch_geometric\n",
    "from utils.BoidDataset import BoidDataset\n",
    "from tqdm import tqdm\n",
    "from time import sleep\n",
    "%matplotlib inline\n",
    "from random import random\n",
    "\n",
    "USE_NORMAL_DIST = True\n",
    "\n",
    "print(torch.__version__)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "###############################\n",
    "###  Gather and split data  ###\n",
    "###############################\n",
    "\n",
    "ta = 70 # Percentage used for training\n",
    "te = 15 # Percentage used for testing (remaining used for validation)\n",
    "\n",
    "try:\n",
    "    shutil.rmtree(\"/tmp/BOIDs\", ignore_errors=False, onerror=None)\n",
    "except FileNotFoundError as e:\n",
    "    pass\n",
    "    \n",
    "x_dataset = BoidDataset(getXData=True,  root='/tmp/BOIDs').shuffle()\n",
    "y_dataset = BoidDataset(getXData=False, root='/tmp/BOIDs').shuffle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(x_dataset))\n",
    "print(x_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "plt.rcParams['figure.figsize'] = [12, 8]\n",
    "\n",
    "numPoints = 10000\n",
    "\n",
    "ranData = np.random.permutation(len(x_dataset)-1)\n",
    "\n",
    "cutDownXData = []\n",
    "cutDownYData = []\n",
    "for i in range(numPoints):\n",
    "    cutDownXData.append(x_dataset[int(ranData[i])])\n",
    "for i in range(numPoints):\n",
    "    cutDownYData.append(y_dataset[int(ranData[i])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1bs7l6xYZl_T",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.functional import F\n",
    "from torch.optim import Adam\n",
    "from torch_geometric.nn import MetaLayer, MessagePassing, GCNConv\n",
    "from torch.nn import Sequential as Seq, Linear as Lin, ReLU, Softplus, Tanh\n",
    "from torch.autograd import Variable, grad\n",
    "\n",
    "import numpy as onp\n",
    "\n",
    "from torch_geometric.nn import TopKPooling\n",
    "from torch_geometric.nn import global_mean_pool as gap, global_max_pool as gmp\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch_geometric.nn import GraphConv, TopKPooling, GatedGraphConv\n",
    "from torch_geometric.nn import global_mean_pool as gap, global_max_pool as gmp\n",
    "\n",
    "VERBOSE = False\n",
    "\n",
    "onp.random.seed(200)\n",
    "recorded_models = []\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [8, 5]\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class EdgeGNN(MessagePassing):\n",
    "    def __init__(self, data, hidden=300, aggr='add'):\n",
    "        \n",
    "        inLen = len(data.x[0])\n",
    "        outLen = len(data.y[0])\n",
    "        edgeLen = len(data.edge_attr[0])\n",
    "        msg_dim = 100\n",
    "        \n",
    "        super(EdgeGNN, self).__init__(aggr=aggr)\n",
    "        \n",
    "        self.msg_fnc = Seq(\n",
    "            Lin(2*inLen+edgeLen, hidden),\n",
    "            ReLU(),\n",
    "            Lin(hidden, hidden),\n",
    "            ReLU(),\n",
    "            Lin(hidden, hidden),\n",
    "            ReLU(),\n",
    "            Lin(hidden, msg_dim)\n",
    "        )\n",
    "        \n",
    "        self.node_fnc = Seq(\n",
    "            Lin(msg_dim+inLen, hidden),\n",
    "            ReLU(),\n",
    "            Lin(hidden, hidden),\n",
    "            ReLU(),\n",
    "            Lin(hidden, hidden),\n",
    "            ReLU(),\n",
    "            Lin(hidden, outLen)\n",
    "        )\n",
    "        \n",
    "    \n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        edge_index = torch.tensor([edge_index[1].tolist(), edge_index[0].tolist()], dtype=torch.long).to(device)\n",
    "        if VERBOSE:\n",
    "            print(\"(flipping edge indexs)\")\n",
    "            print(\"---------------------------\")\n",
    "            print(\"Inside FORWARD\")\n",
    "            print(\"=== Node Embeddings ===\")\n",
    "            for i in range(len(x)):\n",
    "                print(\"node\" + str(i) + \":: \" + str(x[i].item()))\n",
    "            print(\"=== Edge Embeddings ===\")\n",
    "            for i in range(len(edge_attr)):\n",
    "                print(\"From node\" + str(edge_index[0][i].item()) + \" to node\" + str(edge_index[1][i].item()) + \":: \" + str(edge_attr[i]))\n",
    "        result = self.propagate(edge_index, x=x, edge_attr=edge_attr)\n",
    "        if VERBOSE:\n",
    "            print(\"=== Results ===\")\n",
    "            print(len(result))\n",
    "            print(len(result[0]))\n",
    "            print(result)\n",
    "        return result\n",
    "            \n",
    "    def message(self, x_i, x_j, edge_attr):\n",
    "        tmp = torch.cat([x_i, x_j, edge_attr], dim=1)\n",
    "        if VERBOSE:\n",
    "            print(\"---------------------------\")\n",
    "            print(\"Inside MESSAGE\")\n",
    "            print(x_i)\n",
    "            print(x_j)\n",
    "            print(edge_attr)\n",
    "            print(tmp)\n",
    "        return self.msg_fnc(tmp)\n",
    "    \n",
    "    def update(self, aggr_out, x=None):\n",
    "        tmp = torch.cat([x, aggr_out], dim=1)\n",
    "        if VERBOSE:\n",
    "            print(\"---------------------------\")\n",
    "            print(\"Inside UPDATE\")\n",
    "            print(aggr_out)\n",
    "            print(x)\n",
    "            print(tmp)\n",
    "        return self.node_fnc(tmp)\n",
    "    \n",
    "    def loss(self, actual, pred):\n",
    "        retVal = torch.sum(torch.abs(actual[0][0]-pred[0][0]))\n",
    "        if VERBOSE:\n",
    "            print(\"---------------------------\")\n",
    "            print(\"Inside LOSS\")\n",
    "            print(\"Actual\")\n",
    "            print(actual[0][0])\n",
    "            print(\"Pred\")\n",
    "            print(pred[0][0])\n",
    "            print(\"Return\")\n",
    "            print(retVal)\n",
    "        return retVal\n",
    "\n",
    "    \n",
    "    \n",
    "ytrainLoader = DataLoader(y_dataset, batch_size=32, shuffle=True)\n",
    "xtrainLoader = DataLoader(x_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "xHist = []\n",
    "yHist = []\n",
    "for data in xtrainLoader:\n",
    "    xHist.append(data.y[0][0].item())\n",
    "for data in ytrainLoader:\n",
    "    yHist.append(data.y[0][0].item())\n",
    "\n",
    "LR = 0.0001\n",
    "\n",
    "xMod = EdgeGNN(cutDownXData[0])\n",
    "yMod = EdgeGNN(cutDownYData[0])\n",
    "\n",
    "xMod = xMod.to(device)\n",
    "yMod = yMod.to(device)\n",
    "\n",
    "xMod.train()\n",
    "yMod.train()\n",
    "\n",
    "xOptimizer = torch.optim.Adam(xMod.parameters(), lr=LR, weight_decay=5e-8)\n",
    "yOptimizer = torch.optim.Adam(yMod.parameters(), lr=LR, weight_decay=5e-8)\n",
    "\n",
    "num_epochs = 30\n",
    "epoch = 0\n",
    "losses = []\n",
    "\n",
    "for epoch in tqdm(range(epoch, num_epochs)):\n",
    "\n",
    "    xMod.to(device)\n",
    "    yMod.to(device)\n",
    "\n",
    "    xMod.train()\n",
    "    yMod.train()\n",
    "\n",
    "    x_total_loss = 0.0\n",
    "    y_total_loss = 0.0\n",
    "    \n",
    "    xPredHist = []\n",
    "    yPredHist = []\n",
    "    \n",
    "    num_items = 0\n",
    "    i=0\n",
    "    total_loss = 0\n",
    "    \n",
    "    for data in xtrainLoader:\n",
    "\n",
    "        xOptimizer.zero_grad()\n",
    "        \n",
    "        data.x = data.x.to(device)\n",
    "        data.edge_index = data.edge_index.to(device)\n",
    "        data.edge_attr = data.edge_attr.to(device)\n",
    "        data.y = data.y.to(device)\n",
    "        data.batch = data.batch.to(device)\n",
    "        \n",
    "        xPred = xMod(data.x, data.edge_index, data.edge_attr)\n",
    "        xPredHist.append(xPred[0][0].item())\n",
    "        xLoss = xMod.loss(data.y, xPred)\n",
    "        (xLoss/int(data.batch[-1]+1)).backward()\n",
    "        x_total_loss += xLoss.item()\n",
    "        xOptimizer.step()\n",
    "    \n",
    "        total_loss += xLoss.item()\n",
    "        i += 1\n",
    "        num_items += int(data.batch[-1]+1)\n",
    "\n",
    "    for data in ytrainLoader:\n",
    "    \n",
    "        yOptimizer.zero_grad()\n",
    "        yPred = yMod(data.x.to(device), data.edge_index.to(device), data.edge_attr.to(device))\n",
    "        yPredHist.append(yPred[0][0].item())\n",
    "        yLoss = yMod.loss(data.y.to(device), yPred)\n",
    "        (yLoss/int(data.batch.to(device)[-1]+1)).backward()\n",
    "        y_total_loss += yLoss.item()\n",
    "        yOptimizer.step()\n",
    "\n",
    "        if VERBOSE:\n",
    "            raise Exception\n",
    "\n",
    "\n",
    "    cur_loss = total_loss/num_items\n",
    "    print(\"{during: \" + str(cur_loss) + \"}\")\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "\n",
    "    ax1.hist(xHist, 500, density=True, facecolor='g', alpha=0.25)\n",
    "    ax1.hist(xPredHist, 500, density=True, facecolor='b', alpha=0.25)\n",
    "    \n",
    "    ax2.hist(yHist, 500, density=True, facecolor='g', alpha=0.25)\n",
    "    ax2.hist(yPredHist, 500, density=True, facecolor='b', alpha=0.25)\n",
    "    \n",
    "    fig.show()\n",
    "    plt.show()\n",
    "    \n",
    "    losses.append([cur_loss])#, y_total_loss])\n",
    "    sleep(0.5)\n",
    "    \n",
    "    torch.save(xMod.state_dict(), './models/boid-models/xBOID'+str(epoch)+'.mod')\n",
    "    torch.save(yMod.state_dict(), './models/boid-models/yBOID'+str(epoch)+'.mod')\n",
    "    \n",
    "torch.save(xMod.state_dict(), './models/boid-models/xBOID_FINAL.mod')\n",
    "torch.save(yMod.state_dict(), './models/boid-models/yBOID_FINAL.mod')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([i for i in range(len(losses))],[losses[i][0] for i in range(len(losses))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nNeighbors = 1\n",
    "numPoints = 5000\n",
    "\n",
    "from random import random\n",
    "import math\n",
    "from math import sqrt\n",
    "\n",
    "dataListX = []\n",
    "dataListY = []\n",
    "dataListXA = []\n",
    "dataListYA = []\n",
    "\n",
    "visRange = 100\n",
    "MAXSPEED = 3\n",
    "results = []\n",
    "\n",
    "for i in range(numPoints):\n",
    "    rowX = []\n",
    "    rowY = []\n",
    "    \n",
    "    data = [[1.] for _ in range(nNeighbors+1)]\n",
    "    \n",
    "    myX = random() * 400\n",
    "    myY = random() * 400\n",
    "    myT = random()*2*math.pi\n",
    "    myS = random() * MAXSPEED\n",
    "    myXa = math.cos(myT) * myS\n",
    "    myYa = math.sin(myT) * myS\n",
    "        \n",
    "    e1 = []\n",
    "    e2 = []\n",
    "    att = []\n",
    "    for j in range(1, nNeighbors+1):  \n",
    "        \n",
    "        distance = random() * visRange\n",
    "        speed = random() * MAXSPEED\n",
    "        azi = random()*2*math.pi\n",
    "        theta = random()*2*math.pi\n",
    "        inXa = math.cos(theta)*speed\n",
    "        inYa = math.sin(theta)*speed\n",
    "        inX = (myX + distance*math.cos(azi))\n",
    "        inY = (myY + distance*math.sin(azi))\n",
    "        \n",
    "        x12 =(inX-myX)*(myXa/myS) - (inY-myY)*(myYa/myS)\n",
    "        y12 =(inX-myX)*(myYa/myS) + (inY-myY)*(myXa/myS)\n",
    "        xd12 = (inXa-myXa)\n",
    "        yd12 = (inYa-myYa)\n",
    "        d = distance\n",
    "        \n",
    "        # Conversion to standard naming\n",
    "        lFX = x12\n",
    "        lFY = y12\n",
    "        lFXD = xd12\n",
    "        lFYD = yd12\n",
    "        d = sqrt(pow(lFX, 2) + pow(lFY, 2))\n",
    "        s = sqrt(pow(lFXD, 2) + pow(lFYD, 2))\n",
    "        invd = 1.0 / d\n",
    "        invs = 0\n",
    "        if s != 0:\n",
    "            invs = 1.0 / s\n",
    "        lFnX = lFX * invd\n",
    "        lFnY = lFY * invd\n",
    "        lFnXD = lFXD * invs\n",
    "        lFnYD = lFYD * invs\n",
    "        \n",
    "        e1.extend([j])\n",
    "        e2.extend([0])\n",
    "        att.append([lFX, lFY, d, invd, lFnX, lFnY, lFXD, lFYD, s, invs, lFnXD, lFnYD])\n",
    "        rowX.extend([lFX, d, invd, lFnX, lFXD, s, invs, lFnXD])\n",
    "        rowY.extend([lFY, d, invd, lFnY, lFYD, s, invs, lFnYD])\n",
    "    \n",
    "    x = torch.tensor(data, dtype=torch.float).to(device)\n",
    "    e = torch.tensor([e1, e2], dtype=torch.long).to(device)\n",
    "    a = torch.tensor(att, dtype=torch.float).to(device)\n",
    "    \n",
    "    xPred = xMod(x, e, a)\n",
    "    yPred = yMod(x, e, a)\n",
    "    newXVel = (xPred[0][0].item() - 0.5) * 4.0\n",
    "    newYVel = (yPred[0][0].item() - 0.5) * 8.0\n",
    "    \n",
    "    xaData = []\n",
    "    xaData.extend(rowX)\n",
    "    xaData.append(newXVel)\n",
    "    \n",
    "    yaData = []\n",
    "    yaData.extend(rowY)\n",
    "    yaData.append(newYVel)\n",
    "        \n",
    "    dataListXA.append(xaData)\n",
    "    dataListYA.append(yaData)\n",
    "    dataListYA.append(xaData)\n",
    "\n",
    "xaFile = ''\n",
    "for i in range(len(dataListXA)): \n",
    "    xaStr = ''\n",
    "    for j in range(len(dataListXA[i])):\n",
    "        xaStr += str(dataListXA[i][j]) + \",\"\n",
    "    xaStr = xaStr[:-1] + \"\\n\"\n",
    "    xaFile+=xaStr\n",
    "    \n",
    "yaFile = ''\n",
    "for i in range(len(dataListYA)): \n",
    "    yaStr = ''\n",
    "    for j in range(len(dataListYA[i])):\n",
    "        yaStr += str(dataListYA[i][j]) + \",\"\n",
    "    yaStr = yaStr[:-1] + \"\\n\"\n",
    "    yaFile+=yaStr\n",
    "    \n",
    "with open(\"./data/MME-data/xBOIDoutdata.csv\", 'w') as f:\n",
    "    f.write(xaFile)\n",
    "    print(\"writing\")\n",
    "with open(\"./data/MME-data/yBOIDoutdata.csv\", 'w') as f:\n",
    "    f.write(yaFile)\n",
    "    print(\"writing\")\n",
    "\n",
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "lEKUuuYfTjP5",
    "IXpsg0LUb2sT",
    "9RTQhSJDbfLZ",
    "kdgdkJwFZl-V",
    "Zw9W7SB-Zl-i",
    "ARWJg6SbZl-n",
    "1PRxdcqSZl-z",
    "Fz05x2HLT5Kg",
    "kBtdfcvgZl_F",
    "gTHRRgTuZl_K",
    "g46wRgIWZl_S",
    "RszfVgfhZl_a",
    "WK5_u9F7UttT",
    "yyduWbndZl_e",
    "hSqOrC1WZl_l",
    "w12Qg4t_em8w",
    "Y4EzD79nU8DO",
    "Uxtqu4E4erXd"
   ],
   "name": "GN_Demo",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
